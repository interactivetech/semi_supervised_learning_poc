{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5acad626-fca5-4192-b941-c57744ee7910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn to draw gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f2dbfbc-95a6-4c6b-a2d8-04329350e5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision.ops import nms, box_convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09bae1f3-3590-4f37-a723-7c23db40c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75dcb36c-7455-4367-81ae-a2461dfa1fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_radius(det_size, min_overlap=0.7):\n",
    "  height, width = det_size\n",
    "\n",
    "  a1  = 1\n",
    "  b1  = (height + width)\n",
    "  c1  = width * height * (1 - min_overlap) / (1 + min_overlap)\n",
    "  sq1 = np.sqrt(b1 ** 2 - 4 * a1 * c1)\n",
    "  r1  = (b1 + sq1) / 2\n",
    "\n",
    "  a2  = 4\n",
    "  b2  = 2 * (height + width)\n",
    "  c2  = (1 - min_overlap) * width * height\n",
    "  sq2 = np.sqrt(b2 ** 2 - 4 * a2 * c2)\n",
    "  r2  = (b2 + sq2) / 2\n",
    "\n",
    "  a3  = 4 * min_overlap\n",
    "  b3  = -2 * min_overlap * (height + width)\n",
    "  c3  = (min_overlap - 1) * width * height\n",
    "  sq3 = np.sqrt(b3 ** 2 - 4 * a3 * c3)\n",
    "  r3  = (b3 + sq3) / 2\n",
    "  return min(r1, r2, r3)\n",
    "\n",
    "def gaussian_radius2(det_size, min_overlap):\n",
    "    height, width = det_size\n",
    "\n",
    "    a1  = 1\n",
    "    b1  = (height + width)\n",
    "    c1  = width * height * (1 - min_overlap) / (1 + min_overlap)\n",
    "    sq1 = np.sqrt(b1 ** 2 - 4 * a1 * c1)\n",
    "    r1  = (b1 - sq1) / (2 * a1)\n",
    "\n",
    "    a2  = 4\n",
    "    b2  = 2 * (height + width)\n",
    "    c2  = (1 - min_overlap) * width * height\n",
    "    sq2 = np.sqrt(b2 ** 2 - 4 * a2 * c2)\n",
    "    r2  = (b2 - sq2) / (2 * a2)\n",
    "\n",
    "    a3  = 4 * min_overlap\n",
    "    b3  = -2 * min_overlap * (height + width)\n",
    "    c3  = (min_overlap - 1) * width * height\n",
    "    sq3 = np.sqrt(b3 ** 2 - 4 * a3 * c3)\n",
    "    r3  = (b3 + sq3) / (2 * a3)\n",
    "    return min(r1, r2, r3)\n",
    "def gaussian2D(shape, sigma=1):\n",
    "    m, n = [(ss - 1.) / 2. for ss in shape]\n",
    "    y, x = np.ogrid[-m:m+1,-n:n+1]\n",
    "\n",
    "    h = np.exp(-(x * x + y * y) / (2 * sigma * sigma))\n",
    "    h[h < np.finfo(h.dtype).eps * h.max()] = 0\n",
    "    return h\n",
    "\n",
    "def draw_umich_gaussian(heatmap, center, radius, k=1):\n",
    "  diameter = 2 * radius + 1\n",
    "  gaussian = gaussian2D((diameter, diameter), sigma=diameter / 6)\n",
    "  # print(gaussian.shape)\n",
    "  x, y = int(center[0]), int(center[1])\n",
    "\n",
    "  height, width = heatmap.shape[0:2]\n",
    "    \n",
    "  left, right = min(x, radius), min(width - x, radius + 1)\n",
    "  top, bottom = min(y, radius), min(height - y, radius + 1)\n",
    "\n",
    "  masked_heatmap  = heatmap[y - top:y + bottom, x - left:x + right]\n",
    "  masked_gaussian = gaussian[radius - top:radius + bottom, radius - left:radius + right]\n",
    "  if min(masked_gaussian.shape) > 0 and min(masked_heatmap.shape) > 0: # TODO debug\n",
    "    np.maximum(masked_heatmap, masked_gaussian * k, out=masked_heatmap)\n",
    "  return heatmap\n",
    "def draw_dense_reg(regmap, heatmap, center, value, radius, is_offset=False):\n",
    "  diameter = 2 * radius + 1\n",
    "  gaussian = gaussian2D((diameter, diameter), sigma=diameter / 6)\n",
    "  value = np.array(value, dtype=np.float32).reshape(-1, 1, 1)\n",
    "\n",
    "  dim = value.shape[0]\n",
    "  reg = np.ones((dim, diameter*2+1, diameter*2+1), dtype=np.float32) * value\n",
    "\n",
    "  if is_offset and dim == 2:\n",
    "    delta = np.arange(diameter*2+1) - radius\n",
    "    reg[0] = reg[0] - delta.reshape(1, -1)\n",
    "    reg[1] = reg[1] - delta.reshape(-1, 1)\n",
    "  \n",
    "  x, y = int(center[0]), int(center[1])\n",
    "\n",
    "  height, width = heatmap.shape[0:2]\n",
    "\n",
    "  left, right = min(x, radius), min(width - x, radius + 1)\n",
    "  top, bottom = min(y, radius), min(height - y, radius + 1)\n",
    "\n",
    "  masked_heatmap = heatmap[y - top:y + bottom, x - left:x + right]\n",
    "  masked_regmap = regmap[:, y - top:y + bottom, x - left:x + right]\n",
    "  masked_gaussian = gaussian[radius - top:radius + bottom,\n",
    "                             radius - left:radius + right]\n",
    "  masked_reg = reg[:, radius - top:radius + bottom,\n",
    "                      radius - left:radius + right]\n",
    "\n",
    "  if min(masked_gaussian.shape) > 0 and min(masked_heatmap.shape) > 0: # TODO debug\n",
    "    idx = (masked_gaussian >= masked_heatmap).reshape(\n",
    "      1, masked_gaussian.shape[0], masked_gaussian.shape[1])\n",
    "    masked_regmap = (1-idx) * masked_regmap + idx * masked_reg\n",
    "  regmap[:, y - top:y + bottom, x - left:x + right] = masked_regmap\n",
    "  return regmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55ffd302-23cb-4ae5-963c-1748d08752da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "97 95\n",
      "32 32\n",
      "(2, 64, 64)\n",
      "hm.shape: (2, 64, 64), regr.shape: (2, 64, 64), wh_regr.shape: (2, 64, 64), w_h_.shape: (128, 2),inds.shape: (128,), ind_masks.shape: (128,)\n",
      "[1950 2080 1755    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "tensor([[[30.0000, 30.0000],\n",
      "         [32.5000, 33.5000],\n",
      "         [27.0000, 27.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000]]])\n",
      "22\n",
      "8\n",
      "19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9c13d64880>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hm = np.zeros((2,128,128))\n",
    "input_size = 128\n",
    "MODEL_SCALE=2\n",
    "# cs = np.array([[60,60,32,32],[64,64,96,96],[54,54,32,32]])\n",
    "boxes = np.array([[44,44,76,76],\n",
    "                  [16,18,113,113],\n",
    "                  [38,38,70,70]])\n",
    "\n",
    "classes = np.array([0,1,0])\n",
    "# c = np.array([64,64,100,100])\n",
    "# print(cs.shape)\n",
    "\n",
    "# hm_vis = hm.copy()\n",
    "\n",
    "def encode_hm_regr_and_wh_regr(boxes, classes,N_CLASSES=None, input_size=None,MODEL_SCALE=None):\n",
    "    '''\n",
    "    '''\n",
    "    max_objs=128\n",
    "    fmap_dim = input_size//MODEL_SCALE\n",
    "    hm = np.zeros((N_CLASSES,fmap_dim,fmap_dim),dtype=np.float32)\n",
    "    regr = np.zeros((2, fmap_dim, fmap_dim), dtype=np.float32)\n",
    "    wh_regr = np.zeros((2, fmap_dim, fmap_dim), dtype=np.float32)\n",
    "    inds = np.zeros((max_objs,), dtype=np.int64)\n",
    "    ind_masks = np.zeros((max_objs,), dtype=np.uint8)\n",
    "    w_h_ = np.zeros((max_objs, 2), dtype=np.float32)  # width and height\n",
    "    for ind,(c,cl) in enumerate(zip(boxes,classes)):\n",
    "        x,y,x2,y2 = c\n",
    "        w = int(x2-x)\n",
    "        h = int(y2-y)\n",
    "        print(w,h)\n",
    "        centers = [(x+x2)/2.,(y+y2)/2.]\n",
    "        # print(\"centers: \",centers)\n",
    "        c_s = np.array([i/MODEL_SCALE for i in centers])\n",
    "        # print(\"c_s: \",c_s)\n",
    "        centers_int = c_s.copy().astype(np.int32)\n",
    "        # print(\"centers_int: \",centers_int)\n",
    "        # centers_sc = np.array([int(i)//MODEL_SCALE for i in c_s],dtype=np.float32)\n",
    "        # print(\"centers-centers_int: \",centers-centers_int)\n",
    "        radius = gaussian_radius2((math.ceil(h//MODEL_SCALE), math.ceil(w//MODEL_SCALE)),min_overlap=1.0)\n",
    "        radius = max(0, int(radius))\n",
    "        draw_umich_gaussian(hm[cl], centers_int, \n",
    "                                radius)\n",
    "        draw_dense_reg(wh_regr,hm[cl],c_s,np.array([w,h],dtype=np.float32),radius)\n",
    "        draw_dense_reg(regr,hm[cl],c_s,centers-centers_int,radius)\n",
    "        w_h_[ind] = 1. * w, 1. * h\n",
    "        inds[ind] = centers_int[1] * fmap_dim + centers_int[0]\n",
    "        ind_masks[ind] = 1\n",
    "    \n",
    "    return hm, regr, wh_regr, w_h_,inds, ind_masks\n",
    "\n",
    "def visualize_gt_on_output(boxes, classes,hm,MODEL_SCALE=None):\n",
    "    '''\n",
    "    '''\n",
    "    hm_vis = hm.sum(0)\n",
    "    for b,cl in zip(boxes, classes):\n",
    "        x,y,x2,y2 = b\n",
    "        w = int(x2-x)\n",
    "        h = int(y2-y)\n",
    "        centers = [(x+x2)/2,(y+y2)/2]\n",
    "        c_s = np.array([int(i//MODEL_SCALE) for i in centers]).astype(np.int32)\n",
    "        print(c_s[0]-w//MODEL_SCALE//2)\n",
    "        cv2.rectangle(hm_vis,(c_s[0]-w//MODEL_SCALE//2,c_s[1]-h//MODEL_SCALE//2),(c_s[0]+w//MODEL_SCALE//2,c_s[1]+h//MODEL_SCALE//2),1)\n",
    "    return hm_vis\n",
    "\n",
    "hm, regr, wh_regr, w_h_,inds, ind_masks= encode_hm_regr_and_wh_regr(boxes, classes,N_CLASSES=2, input_size=128,MODEL_SCALE=2)\n",
    "print(hm.shape)\n",
    "print(\"hm.shape: {}, regr.shape: {}, wh_regr.shape: {}, w_h_.shape: {},inds.shape: {}, ind_masks.shape: {}\".format(hm.shape, \n",
    "                                                                                               regr.shape, \n",
    "                                                                                               wh_regr.shape, \n",
    "                                                                                               w_h_.shape,\n",
    "                                                                                               inds.shape, \n",
    "                                                                                               ind_masks.shape))\n",
    "# print(inds)\n",
    "# print(_tranpose_and_gather_feature(torch.from_numpy(regr).unsqueeze(0),torch.from_numpy(inds).unsqueeze(0)))\n",
    "plt.imshow(visualize_gt_on_output(boxes, classes,hm,MODEL_SCALE=2),cmap='gray')\n",
    "\n",
    "# plt.imshow(hm[0]*255,cmap='gray')\n",
    "# plt.show()\n",
    "# plt.imshow(hm[1]*255,cmap='gray')\n",
    "# plt.show()\n",
    "# plt.imshow(hm_vis[0]+hm_vis[1],cmap='gray')\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(wh_regr.transpose(1,2,0)[:,:,0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c256d108-18bf-40ad-9f16-f3e9f3d2ce04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21baaf58-de4d-4b4b-b29f-e6e4e6517b33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7736857e-9d1b-4739-b4be-af4c94a633fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hm_vis_2 = hm.copy()\n",
    "# boxes, scores = pred2box(torch.from_numpy(hm),torch.from_numpy(wh_regr),threshold=0.99, scale=1,input_size=128)\n",
    "# for ind,(b,s) in enumerate(zip(boxes, scores)):\n",
    "#     cx,cy,w,h = [int(i) for i in b.numpy()]\n",
    "#     print(cx,cy,w,h)\n",
    "#     cv2.rectangle(hm_vis_2, (cx-w//2,cy-h//2),(cx+w//2,cy+h//2),1)\n",
    "# plt.imshow(hm_vis_2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0078fd7c-9376-42e5-a5e6-c9037bf0b4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 16.,  18., 113., 113.],\n",
      "        [ 38.,  38.,  70.,  70.],\n",
      "        [ 44.,  44.,  76.,  76.]]) tensor([1., 1., 1.]) tensor([1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "def nonempty(boxes,threshold: float = 0.0) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Find boxes that are non-empty.\n",
    "        A box is considered empty, if either of its side is no larger than threshold.\n",
    "        Returns:\n",
    "            Tensor:\n",
    "                a binary vector which represents whether each box is empty\n",
    "                (False) or non-empty (True).\n",
    "        \"\"\"\n",
    "        widths = boxes[:, 2] - boxes[:, 0]\n",
    "        heights = boxes[:, 3] - boxes[:, 1]\n",
    "        keep = (widths > threshold) & (heights > threshold)\n",
    "        return keep\n",
    "\n",
    "def _gather_feature(feat, ind, mask=None):\n",
    "  dim = feat.size(2)\n",
    "  ind = ind.unsqueeze(2).expand(ind.size(0), ind.size(1), dim)\n",
    "  feat = feat.gather(1, ind)\n",
    "  if mask is not None:\n",
    "    mask = mask.unsqueeze(2).expand_as(feat)\n",
    "    feat = feat[mask]\n",
    "    feat = feat.view(-1, dim)\n",
    "  return feat\n",
    "\n",
    "\n",
    "def _tranpose_and_gather_feature(feat, ind):\n",
    "  feat = feat.permute(0, 2, 3, 1).contiguous()\n",
    "  feat = feat.view(feat.size(0), -1, feat.size(3))\n",
    "  feat = _gather_feature(feat, ind)\n",
    "  return feat\n",
    "\n",
    "def _topk(scores, K=40):\n",
    "  batch, cat, height, width = scores.size()\n",
    "\n",
    "  topk_scores, topk_inds = torch.topk(scores.view(batch, cat, -1), K)\n",
    "\n",
    "  topk_inds = topk_inds % (height * width)\n",
    "  topk_ys = (topk_inds / width).int().float()\n",
    "  topk_xs = (topk_inds % width).int().float()\n",
    "\n",
    "  topk_score, topk_ind = torch.topk(topk_scores.view(batch, -1), K)\n",
    "  topk_clses = (topk_ind / K).int()\n",
    "  topk_inds = _gather_feature(topk_inds.view(batch, -1, 1), topk_ind).view(batch, K)\n",
    "  topk_ys = _gather_feature(topk_ys.view(batch, -1, 1), topk_ind).view(batch, K)\n",
    "  topk_xs = _gather_feature(topk_xs.view(batch, -1, 1), topk_ind).view(batch, K)\n",
    "\n",
    "  return topk_score, topk_inds, topk_clses, topk_ys, topk_xs\n",
    "\n",
    "def decode_predictions(hm,regr,wh_regr,MODEL_SCALE=None,K=100):\n",
    "    '''\n",
    "    hm: BxCxHxW\n",
    "    regr: Bx2xHxW\n",
    "    wh_regr: Bx2xHxW\n",
    "    '''\n",
    "    \n",
    "    batch,cat, height, width = hm.shape\n",
    "\n",
    "    scores, inds, clses, ys, xs = _topk(hm, K=K)\n",
    "\n",
    "    regs = _tranpose_and_gather_feature(regr, inds)\n",
    "    regs = regs.view(batch, K, 2)\n",
    "    # print(regs.shape)\n",
    "    # print(xs.view(batch, K, 1))\n",
    "    # print(xs.view(batch, K, 1)*MODEL_SCALE)\n",
    "    # print(xs.view(batch, K, 1)*MODEL_SCALE+regs[:, :, 0:1])\n",
    "    xs = xs.view(batch, K, 1)+regs[:, :, 0:1]\n",
    "    ys = ys.view(batch, K, 1)+regs[:, :, 1:2]\n",
    "    # print(xs)\n",
    "\n",
    "\n",
    "    w_h_ = _tranpose_and_gather_feature(wh_regr, inds)\n",
    "    w_h_ = w_h_.view(batch, K, 2)\n",
    "    # print(ys)\n",
    "    # print(w_h_ /2)\n",
    "    clses = clses.view(batch, K, 1).float().squeeze(0).squeeze(-1)\n",
    "    scores = scores.view(batch, K, 1).squeeze(0).squeeze(-1).type(torch.float32)\n",
    "    boxes = torch.cat([xs - w_h_[..., 0:1] / 2,\n",
    "                      ys - w_h_[..., 1:2] / 2,\n",
    "                      xs + w_h_[..., 0:1] / 2,\n",
    "                      ys + w_h_[..., 1:2] / 2], dim=2).squeeze(0)\n",
    "\n",
    "    keep = nonempty(boxes)\n",
    "    boxes=boxes[keep]\n",
    "    scores=scores[keep]\n",
    "    clses = clses[keep]\n",
    "    # idx = nms(boxes, scores, 0.5)\n",
    "    # boxes = boxes[idx]\n",
    "    # scores = scores[idx]\n",
    "    # clses = clses[idx]\n",
    "    \n",
    "    return boxes,scores,clses\n",
    "\n",
    "hm_b = torch.from_numpy(hm).unsqueeze(0)\n",
    "regr_b = torch.from_numpy(regr).unsqueeze(0)\n",
    "wh_regr_b = torch.from_numpy(wh_regr).unsqueeze(0)\n",
    "boxes,scores,clses = decode_predictions(hm_b,regr_b,wh_regr_b,MODEL_SCALE=MODEL_SCALE,K=100)\n",
    "'''\n",
    "boxes = np.array([[44,44,76,76],\n",
    "                  [15,17,113,113],\n",
    "                  [38,38,70,70]])\n",
    "'''\n",
    "print(boxes,scores,clses)\n",
    "# if want coco representation: \n",
    "# box_cxcywh = box_convert(boxes, in_fmt=\"xyxy\", out_fmt=\"cxcywh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ff54b7-a548-4b07-ae93-3f805c432c50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe6562b2-b6c8-4b1f-a5c9-4c65b3198874",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# def process_centernet_output(\n",
    "#     predicted_heatmap,  # logits\n",
    "#     predicted_regression,\n",
    "#     gt_boxes,\n",
    "#     gt_labels,\n",
    "#     confidence_threshold=0.5,\n",
    "#     iou_threshold=0.5,\n",
    "# ):\n",
    "#     \"\"\"Generate bbox and classes from CenterNet model outputs.\n",
    "#     Args:\n",
    "#         predicted_heatmap (torch.Tensor): predicted center heatmap logits,\n",
    "#             expected shapes [batch, height, width, num classes].\n",
    "#         predicted_regression (torch.Tensor): predicted HW regression,\n",
    "#             expected shapes [batch, height, width, 2].\n",
    "#         gt_boxes (List[torch.Tensor]): list with sample bounding boxes.\n",
    "#         gt_labels (List[torch.Tensor]): list with sample bounding box labels.\n",
    "#         confidence_threshold (float): confidence threshold,\n",
    "#             proposals with lover values than threshold will be ignored.\n",
    "#             Default is ``0.5``.\n",
    "#         iou_threshold (float): IoU threshold to use in NMS.\n",
    "#             Default is ``0.5``.\n",
    "#     Yields:\n",
    "#         predicted sample (np.ndarray) and ground truth sample (np.ndarray)\n",
    "#     \"\"\"\n",
    "#     batch_size = predicted_heatmap.size(0)\n",
    "\n",
    "#     hm = predicted_heatmap.sigmoid()\n",
    "#     pooled = F.max_pool2d(hm, kernel_size=(3, 3), stride=1, padding=1)\n",
    "#     hm *= torch.logical_and(\n",
    "#         hm >= confidence_threshold, pooled >= confidence_threshold\n",
    "#     ).float()\n",
    "\n",
    "#     hm_numpy = hm.detach().cpu().numpy()\n",
    "#     reg_numpy = predicted_regression.detach().cpu().numpy()\n",
    "\n",
    "#     for i in range(batch_size):\n",
    "#         sample_boxes = []\n",
    "#         sample_classes = []\n",
    "#         sample_scores = []\n",
    "#         for cls_idx in range(hm_numpy.shape[1]):\n",
    "#             # build predictions\n",
    "#             cls_boxes, cls_scores = pred2box(\n",
    "#                 hm_numpy[i, cls_idx], reg_numpy[i], threshold=0, scale=4, input_size=512\n",
    "#             )\n",
    "\n",
    "#             # skip empty label predictions\n",
    "#             if cls_scores.shape[0] == 0:\n",
    "#                 continue\n",
    "\n",
    "#             cls_boxes = cls_boxes / 512.0\n",
    "\n",
    "#             cls_boxes, cls_classes, cls_scores = nms_filter(\n",
    "#                 cls_boxes,\n",
    "#                 np.full(len(cls_scores), cls_idx),\n",
    "#                 cls_scores,\n",
    "#                 iou_threshold=iou_threshold,\n",
    "#             )\n",
    "#             sample_boxes.append(cls_boxes)\n",
    "#             sample_classes.append(cls_classes)\n",
    "#             sample_scores.append(cls_scores)\n",
    "#         # skip empty predictions\n",
    "#         if len(sample_boxes) == 0:\n",
    "#             continue\n",
    "\n",
    "#         sample_boxes = np.concatenate(sample_boxes, 0)\n",
    "#         sample_classes = np.concatenate(sample_classes, 0)\n",
    "#         sample_scores = np.concatenate(sample_scores, 0)\n",
    "\n",
    "#         pred_sample = np.concatenate(\n",
    "#             [sample_boxes, sample_classes[:, None], sample_scores[:, None]], -1\n",
    "#         )\n",
    "#         pred_sample = pred_sample.astype(np.float32)\n",
    "\n",
    "#         sample_gt_bboxes = gt_boxes[i].detach().cpu()\n",
    "#         sample_gt_classes = gt_labels[i].detach().cpu()\n",
    "#         gt_sample = np.zeros((sample_gt_classes.shape[0], 7), dtype=np.float32)\n",
    "#         gt_sample[:, :4] = sample_gt_bboxes\n",
    "#         gt_sample[:, 4] = sample_gt_classes\n",
    "\n",
    "#         yield pred_sample, gt_sample\n",
    "# class CenterNetDataset(Dataset):\n",
    "#     def __init__(self, coco_json_path, images_dir=None, transforms=None, down_ratio=4):\n",
    "#         self.file = coco_json_path\n",
    "#         self.img_dir = images_dir\n",
    "#         self.transforms = transforms\n",
    "#         self.down_ratio = down_ratio\n",
    "\n",
    "#         self.images, self.categories = load_coco_json(coco_json_path)\n",
    "#         self.images_list = sorted(self.images.keys())\n",
    "\n",
    "#         self.class_to_cid = {\n",
    "#             cls_idx: cat_id\n",
    "#             for cls_idx, cat_id in enumerate(sorted(self.categories.keys()))\n",
    "#         }\n",
    "#         self.cid_to_class = {v: k for k, v in self.class_to_cid.items()}\n",
    "#         self.num_classes = len(self.class_to_cid)\n",
    "#         self.class_labels = [\n",
    "#             self.categories[self.class_to_cid[cls_idx]]\n",
    "#             for cls_idx in range(len(self.class_to_cid))\n",
    "#         ]\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.images_list)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         img_id = self.images_list[index]\n",
    "#         img_record = self.images[img_id]\n",
    "\n",
    "#         path = img_record[\"file_name\"]\n",
    "#         if self.img_dir is not None:\n",
    "#             path = os.path.join(self.img_dir, path)\n",
    "#         image = read_image(path)\n",
    "#         original_size = [image.shape[0], image.shape[1]]  # height, width\n",
    "\n",
    "#         boxes = []  # each element is a tuple of (x1, y1, x2, y2, \"class\")\n",
    "#         for annotation in img_record[\"annotations\"]:\n",
    "#             pixel_xywh = annotation[\"bbox\"]\n",
    "#             # skip bounding boxes with 0 height or 0 width\n",
    "#             if pixel_xywh[2] == 0 or pixel_xywh[3] == 0:\n",
    "#                 continue\n",
    "#             xyxy = pixels_to_absolute(\n",
    "#                 pixel_xywh, width=img_record[\"width\"], height=img_record[\"height\"]\n",
    "#             )\n",
    "#             xyxy = clip(xyxy, 0.0, 1.0)\n",
    "#             bbox_class = str(self.cid_to_class[annotation[\"category_id\"]])\n",
    "#             boxes.append(xyxy + [str(bbox_class)])\n",
    "\n",
    "#         if self.transforms is not None:\n",
    "#             transformed = self.transforms(image=image, bboxes=boxes)\n",
    "#             image, boxes = transformed[\"image\"], transformed[\"bboxes\"]\n",
    "#         else:\n",
    "#             image = torch.from_numpy((image / 255.0).astype(np.float32)).permute(2, 0, 1)\n",
    "\n",
    "#         labels = np.array([int(items[4]) for items in boxes])\n",
    "#         boxes = np.array([items[:4] for items in boxes], dtype=np.float32)\n",
    "#         # boxes = change_box_order(boxes, \"xyxy2xywh\")  # (x1, y1, x2, y2) -> (cx, cy, w, h)\n",
    "\n",
    "#         heatmap_height = image.shape[1] // self.down_ratio\n",
    "#         heatmap_width = image.shape[2] // self.down_ratio\n",
    "#         # draw class centers\n",
    "#         heatmap = np.zeros(\n",
    "#             (self.num_classes, heatmap_height, heatmap_width), dtype=np.float32\n",
    "#         )\n",
    "#         for (x1, y1, x2, y2), cls_channel in zip(boxes, labels):\n",
    "#             w, h = abs(x2 - x1), abs(y2 - y1)\n",
    "#             xc, yc = x1 + w // 2, y1 + h // 2\n",
    "#             scaled_xc = int(xc * heatmap_width)\n",
    "#             scaled_yc = int(yc * heatmap_height)\n",
    "#             draw_msra_gaussian(\n",
    "#                 heatmap, cls_channel, (scaled_xc, scaled_yc), sigma=np.clip(w * h, 2, 4)\n",
    "#             )\n",
    "#         # draw regression squares\n",
    "#         wh_regr = np.zeros((2, heatmap_height, heatmap_width), dtype=np.float32)\n",
    "#         regrs = boxes[:, 2:] - boxes[:, :2]  # width, height\n",
    "#         for r, (x1, y1, x2, y2) in zip(regrs, boxes):\n",
    "#             w, h = abs(x2 - x1), abs(y2 - y1)\n",
    "#             xc, yc = x1 + w // 2, y1 + h // 2\n",
    "#             scaled_xc = int(xc * heatmap_width)\n",
    "#             scaled_yc = int(yc * heatmap_height)\n",
    "#             for i in range(-2, 2 + 1):\n",
    "#                 for j in range(-2, 2 + 1):\n",
    "#                     try:\n",
    "#                         a = max(scaled_xc + i, 0)\n",
    "#                         b = min(scaled_yc + j, heatmap_height)\n",
    "#                         wh_regr[:, a, b] = r\n",
    "#                     except:  # noqa: E722\n",
    "#                         pass\n",
    "#         wh_regr[0] = wh_regr[0].T\n",
    "#         wh_regr[1] = wh_regr[1].T\n",
    "\n",
    "#         return {\n",
    "#             \"image\": image,\n",
    "#             \"original_size\": original_size,\n",
    "#             \"size\": [image.size(1), image.size(2)],\n",
    "#             \"heatmap\": torch.from_numpy(heatmap),\n",
    "#             \"wh_regr\": torch.from_numpy(wh_regr),\n",
    "#             \"bboxes\": boxes,\n",
    "#             \"labels\": labels,\n",
    "#         }\n",
    "\n",
    "#     @staticmethod\n",
    "#     def collate_fn(batch):\n",
    "#         keys = list(batch[0].keys())\n",
    "#         packed_batch = {k: [] for k in keys}\n",
    "#         for element in batch:\n",
    "#             for k in keys:\n",
    "#                 packed_batch[k].append(element[k])\n",
    "#         for k in (\"image\", \"heatmap\", \"wh_regr\"):\n",
    "#             packed_batch[k] = torch.stack(packed_batch[k], 0)\n",
    "#         return packed_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c213168-155f-4d89-a342-f5f323f04f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
