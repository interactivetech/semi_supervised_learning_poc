name: test_cifar
entrypoint: >-
  python -m determined.launch.torch_distributed
  python main_det.py
data:
  cl_path: "models/classifier_model/finbert-sentiment"
  cl_data_path: "data/sentiment_data"

hyperparameters:
  base_model: "bert-base-uncased"
  max_seq_length: 48
  train_batch_size: 16 # batch size for each gpu, not global batch size
  learning_rate: 2e-5
  warm_up_proportion: 0.2
  discriminate: True
  gradual_unfreeze: True
  last_layer_to_freeze: 10
  dataset: 'cifar10'
  num_classes: 10
  train_sampler: 'RandomSampler'
  num_workers: 8
  lb_imb_ratio: 1
  ulb_imb_ratio: 1.0
  batch_size:
      type: int
      minval: 32
      maxval: 96
  ulb_num_labels:
    type: categorical
    vals:
     - 150
     - 300
     - 450
     - 600
  img_size: 32
  crop_ratio: 0.875
  num_labels: 30
  seed: 1
  epoch: 10
  num_train_iter: 150
  net: 'wrn_28_8'
  optim: 'SGD'
  lr:
    type: log
    minval: -5
    maxval: -3
    base: 10
  momentum: 0.9
  weight_decay: 0.0005
  layer_decay: 0.75
  num_warmup_iter: 0
  algorithm: None
  data_dir: './data'
  uratio: 3
  eval_batch_size: 64
  

max_restarts: 0
resources:
  slots_per_trial: 1
searcher:
   name: adaptive_asha
   max_trials: 8
   max_length: 50 # this will be the number of epochs in this case
   metric: 'val/F1'
   smaller_is_better: False
   max_concurrent_trials: 4