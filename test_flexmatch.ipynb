{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69997c47-d184-470f-8fad-2792f9501b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f0970f9-f0e7-4be6-93ac-81fc1fa0d9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/usb/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from model import wrn_28_2\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from ema import EMA,EMADriver, set_ema_model\n",
    "from train import trainer\n",
    "from eval import predict, eval\n",
    "from tqdm import tqdm\n",
    "from semilearn import get_dataset, get_data_loader, get_net_builder, get_algorithm, get_config, Trainer\n",
    "from semilearn.datasets.cv_datasets import get_cifar\n",
    "import argparse\n",
    "from semilearn.core.utils import get_dataset, get_data_loader, get_optimizer, get_cosine_schedule_with_warmup\n",
    "import matplotlib.pyplot as plt\n",
    "from flexmatch import FlexMatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8e531f8-af43-432e-b905-b4a65c005dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "lb count: [3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "ulb count: [15, 15, 15, 15, 15, 15, 15, 15, 15, 15]\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "\n",
    "m = wrn_28_2(pretrained=False,pretrained_path=None ,num_classes=10)\n",
    "_=m.to(device)\n",
    "ema = wrn_28_2(pretrained=False,pretrained_path=None ,num_classes=10)\n",
    "ema = set_ema_model(ema, m)\n",
    "emaA = EMADriver(model=m,ema_model=ema,ema_m=0.999)\n",
    "# emaA = EMADriver(model=m,ema_model=ema,ema_m=0.999)\n",
    "emaA.before_run()\n",
    "NUM_CLASSES=10\n",
    "args_d = {'dataset': 'cifar10',\n",
    "         'num_classes': NUM_CLASSES,\n",
    "         'train_sampler': 'RandomSampler',\n",
    "         'num_workers': 0,\n",
    "         'lb_imb_ratio': 1,\n",
    "         'ulb_imb_ratio':1.0,\n",
    "          'batch_size': 32,\n",
    "         'ulb_num_labels': 150,\n",
    "         'img_size': 32,\n",
    "         'crop_ratio': 0.875,\n",
    "         'num_labels': 30,\n",
    "         'seed': 1,\n",
    "         'epoch': 3,\n",
    "         'num_train_iter':150,\n",
    "         'net': 'wrn_28_8',\n",
    "         'optim': 'SGD',\n",
    "         'lr': 0.03,\n",
    "         'momentum': 0.9,\n",
    "         'weight_decay': 0.0005,\n",
    "         'layer_decay': 0.75,\n",
    "          'num_warmup_iter': 0,\n",
    "         'algorithm': None,\n",
    "         'data_dir': './data',\n",
    "         'uratio': 3,\n",
    "         'eval_batch_size': 64}\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Semi-Supervised Learning (USB semilearn package)')\n",
    "args = parser.parse_args(\"\")\n",
    "# args\n",
    "for k in args_d:\n",
    "        setattr(args, k, args_d[k])\n",
    "# lb_dset, ulb_dset, eval_dset = get_cifar(args,\n",
    "#           alg=None, \n",
    "#           name='cifar10',\n",
    "#           num_labels=4000,\n",
    "#           num_classes=10,\n",
    "#           data_dir='./data',\n",
    "#           include_lb_to_ulb=True)\n",
    "dataset_dict = get_dataset(args, \n",
    "                           args.algorithm, \n",
    "                           args.dataset, \n",
    "                           args.num_labels, \n",
    "                           args.num_classes, \n",
    "                           data_dir=args.data_dir,\n",
    "                          include_lb_to_ulb=False)\n",
    "train_lb_loader = get_data_loader(args, dataset_dict['train_lb'], args.batch_size)\n",
    "train_lb_loader = get_data_loader(args, dataset_dict['train_lb'], args.batch_size)\n",
    "train_ulb_loader = get_data_loader(args, dataset_dict['train_ulb'], int(args.batch_size * args.uratio))\n",
    "eval_loader = get_data_loader(args, dataset_dict['eval'], args.eval_batch_size)\n",
    "\n",
    "optimizer = get_optimizer(m, args.optim, args.lr, args.momentum, args.weight_decay, args.layer_decay)\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer,\n",
    "                                            args.num_train_iter,\n",
    "                                            num_warmup_steps=args.num_warmup_iter)\n",
    "loss_ce = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c95d575-3f8b-4d3b-8f8b-716a4f2c34be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = FlexMatch(T, \n",
    "#              p_cutoff, \n",
    "#              ulb_dest_len=len(dataset_dict['train_ulb']),\n",
    "#              num_classes=10,\n",
    "#              model=m)\n",
    "\n",
    "# m = wrn_28_2(pretrained=False,pretrained_path=None ,num_classes=10)\n",
    "# _=m.to(device)\n",
    "# ema = wrn_28_2(pretrained=False,pretrained_path=None ,num_classes=10)\n",
    "# ema = set_ema_model(ema, m)\n",
    "# emaA = EMADriver(model=m,ema_model=ema,ema_m=0.999)\n",
    "# emaA = EMADriver(model=m,ema_model=ema,ema_m=0.999)\n",
    "# emaA.before_run()\n",
    "\n",
    "f = FlexMatch(T=1.0, \n",
    "             p_cutoff=0.95, \n",
    "             ulb_dest_len=len(dataset_dict['train_ulb']),\n",
    "             num_classes=NUM_CLASSES,\n",
    "             model=m,\n",
    "             ema_model=ema,\n",
    "             loss_ce=loss_ce,\n",
    "             scheduler=scheduler,\n",
    "             optimizer=optimizer,\n",
    "             device=device,\n",
    "             train_lb_loader=train_lb_loader,\n",
    "             train_ulb_loader=train_ulb_loader,\n",
    "             ulb_loss_ratio=1.0,\n",
    "             hard_label=True, \n",
    "             thresh_warmup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c5b008-e73d-41ce-ade3-ccc99b1e9fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 83/100 [38:56<07:58, 28.16s/it]"
     ]
    }
   ],
   "source": [
    "steps, sup_loss,unsup_loss,total_loss, mask_ratio = f.fit(epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6866f6c3-8dd2-409e-b8bc-6d182e271989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9febf6-1ac5-41fa-9ead-ee37b2e4ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14daec81-3416-48c9-be18-7641c38548b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(steps,sup_loss)\n",
    "plt.plot(steps,unsup_loss)\n",
    "plt.plot(steps,total_loss)\n",
    "plt.plot(steps,mask_ratio)\n",
    "#mask_ratio\n",
    "plt.legend(['sup_loss','unsup_loss','total_loss','mask_ratio'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0de4e3-dc14-4941-8a8b-e45984a16a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top1,balanced_top1, precision, recall, F1, cf_mat  = eval(m,emaA.ema,eval_loader,device,return_gt=True,use_ema_model=False)\n",
    "no_ema = {\n",
    "    'top1':top1,\n",
    "    'balanced_top1':balanced_top1,\n",
    "    'precision':precision,\n",
    "    'recall':recall,\n",
    "    'F1':F1,\n",
    "    'cf_mat':cf_mat\n",
    "}\n",
    "top1,balanced_top1, precision, recall, F1, cf_mat  = eval(m,emaA.ema,eval_loader,device,return_gt=True,use_ema_model=True)\n",
    "ema_res = {\n",
    "    'top1':top1,\n",
    "    'balanced_top1':balanced_top1,\n",
    "    'precision':precision,\n",
    "    'recall':recall,\n",
    "    'F1':F1,\n",
    "    'cf_mat':cf_mat\n",
    "}\n",
    "for k in ema_res.keys():\n",
    "    if k!='cf_mat':\n",
    "        print(k,no_ema[k],ema_res[k])\n",
    "        plt.bar(['no_ema','ema'],[no_ema[k],ema_res[k]])\n",
    "        plt.title(\"{} No EMA vs EMA\".format(k))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e55045-681b-49ed-9262-df7d1b77a765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5937ed-f756-4cea-ac2e-1f166e6bdf56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb53b87f-a388-4331-9aab-417044308695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usb",
   "language": "python",
   "name": "usb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
