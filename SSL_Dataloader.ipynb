{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84976073-2d21-47ea-ba3c-5a72c6e0139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a005616-d1ae-4387-b60e-c050c83d77dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/usb/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# from semilearn.datasets.cv_datasets.cifar import get_cifar\n",
    "import argparse\n",
    "import os\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from semilearn.datasets.augmentation import RandAugment, RandomResizedCropAndInterpolation\n",
    "from semilearn.datasets.utils import split_ssl_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "160ea67e-8797-4bd3-8f91-e09eadb55c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES=10\n",
    "args_d = {'dataset': 'cifar10',\n",
    "         'num_classes': NUM_CLASSES,\n",
    "         'train_sampler': 'RandomSampler',\n",
    "         'num_workers': 0,\n",
    "         'lb_imb_ratio': 1,\n",
    "         'ulb_imb_ratio':1.0,\n",
    "          'batch_size': 32,\n",
    "         'ulb_num_labels': 150,\n",
    "         'img_size': 32,\n",
    "         'crop_ratio': 0.875,\n",
    "         'num_labels': 30,\n",
    "         'seed': 1,\n",
    "         'epoch': 3,\n",
    "         'num_train_iter':150,\n",
    "         'net': 'wrn_28_8',\n",
    "         'optim': 'SGD',\n",
    "         'lr': 0.03,\n",
    "         'momentum': 0.9,\n",
    "         'weight_decay': 0.0005,\n",
    "         'layer_decay': 0.75,\n",
    "          'num_warmup_iter': 0,\n",
    "         'algorithm': None,\n",
    "         'data_dir': './data',\n",
    "         'uratio': 3,\n",
    "         'eval_batch_size': 64}\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Semi-Supervised Learning (USB semilearn package)')\n",
    "args = parser.parse_args(\"\")\n",
    "# args\n",
    "for k in args_d:\n",
    "        setattr(args, k, args_d[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65c53f2e-8c48-4b7b-8d61-139cf1122704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_cifar(args, None, 'cifar10', 20, 10, data_dir='./data', include_lb_to_ulb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd595aad-979b-4bf8-b3eb-6691aac23ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ca2c4fd-c325-4f69-98c0-59e62ae5b5ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBasicDataset\u001b[39;00m(Dataset):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    BasicDataset returns a pair of image and labels (targets).\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    If targets are not given, BasicDataset returns None as the label.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    This class supports strong augmentation for Fixmatch,\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    and return both weakly and strongly augmented images.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     10\u001b[0m                  alg,\n\u001b[1;32m     11\u001b[0m                  data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m                  \u001b[38;5;241m*\u001b[39margs, \n\u001b[1;32m     19\u001b[0m                  \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class BasicDataset(Dataset):\n",
    "    \"\"\"\n",
    "    BasicDataset returns a pair of image and labels (targets).\n",
    "    If targets are not given, BasicDataset returns None as the label.\n",
    "    This class supports strong augmentation for Fixmatch,\n",
    "    and return both weakly and strongly augmented images.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 alg,\n",
    "                 data,\n",
    "                 targets=None,\n",
    "                 num_classes=None,\n",
    "                 transform=None,\n",
    "                 is_ulb=False,\n",
    "                 strong_transform=None,\n",
    "                 onehot=False,\n",
    "                 *args, \n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Args\n",
    "            data: x_data\n",
    "            targets: y_data (if not exist, None)\n",
    "            num_classes: number of label classes\n",
    "            transform: basic transformation of data\n",
    "            use_strong_transform: If True, this dataset returns both weakly and strongly augmented images.\n",
    "            strong_transform: list of transformation functions for strong augmentation\n",
    "            onehot: If True, label is converted into onehot vector.\n",
    "        \"\"\"\n",
    "        super(BasicDataset, self).__init__()\n",
    "        self.alg = alg\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.is_ulb = is_ulb\n",
    "        self.onehot = onehot\n",
    "\n",
    "        self.transform = transform\n",
    "        self.strong_transform = strong_transform\n",
    "        if self.strong_transform is None:\n",
    "            if self.is_ulb:\n",
    "                assert self.alg not in ['fullysupervised', 'supervised', 'pseudolabel', 'vat', 'pimodel', 'meanteacher', 'mixmatch'], f\"alg {self.alg} requires strong augmentation\"\n",
    "    \n",
    "    def __sample__(self, idx):\n",
    "        \"\"\" dataset specific sample function \"\"\"\n",
    "        # set idx-th target\n",
    "        if self.targets is None:\n",
    "            target = None\n",
    "        else:\n",
    "            target_ = self.targets[idx]\n",
    "            target = target_ if not self.onehot else get_onehot(self.num_classes, target_)\n",
    "\n",
    "        # set augmented images\n",
    "        img = self.data[idx]\n",
    "        return img, target\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        If strong augmentation is not used,\n",
    "            return weak_augment_image, target\n",
    "        else:\n",
    "            return weak_augment_image, strong_augment_image, target\n",
    "        \"\"\"\n",
    "        img, target = self.__sample__(idx)\n",
    "\n",
    "        if self.transform is None:\n",
    "            return  {'x_lb':  transforms.ToTensor()(img), 'y_lb': target}\n",
    "        else:\n",
    "            if isinstance(img, np.ndarray):\n",
    "                img = Image.fromarray(img)\n",
    "            img_w = self.transform(img)\n",
    "            print(\"self.alg: \", self.alg)\n",
    "\n",
    "            if not self.is_ulb:\n",
    "                return {'idx_lb': idx, 'x_lb': img_w, 'y_lb': target} \n",
    "            else:\n",
    "                if self.alg == 'fullysupervised' or self.alg == 'supervised':\n",
    "                    return {'idx_ulb': idx}\n",
    "                elif self.alg == 'pseudolabel' or self.alg == 'vat':\n",
    "                    return {'idx_ulb': idx, 'x_ulb_w':img_w} \n",
    "                elif self.alg == 'pimodel' or self.alg == 'meanteacher' or self.alg == 'mixmatch':\n",
    "                    # NOTE x_ulb_s here is weak augmentation\n",
    "                    return {'idx_ulb': idx, 'x_ulb_w': img_w, 'x_ulb_s': self.transform(img)}\n",
    "                elif self.alg == 'remixmatch':\n",
    "                    rotate_v_list = [0, 90, 180, 270]\n",
    "                    rotate_v1 = np.random.choice(rotate_v_list, 1).item()\n",
    "                    img_s1 = self.strong_transform(img)\n",
    "                    img_s1_rot = torchvision.transforms.functional.rotate(img_s1, rotate_v1)\n",
    "                    img_s2 = self.strong_transform(img)\n",
    "                    return {'idx_ulb': idx, 'x_ulb_w': img_w, 'x_ulb_s_0': img_s1, 'x_ulb_s_1':img_s2, 'x_ulb_s_0_rot':img_s1_rot, 'rot_v':rotate_v_list.index(rotate_v1)}\n",
    "                elif self.alg == 'comatch':\n",
    "                    return {'idx_ulb': idx, 'x_ulb_w': img_w, 'x_ulb_s_0': self.strong_transform(img), 'x_ulb_s_1':self.strong_transform(img)} \n",
    "                else:\n",
    "                    return {'idx_ulb': idx, 'x_ulb_w': img_w, 'x_ulb_s': self.strong_transform(img)} \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628dc764-cb63-4f50-b87b-da37b804f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicDataset2(Dataset):\n",
    "    \"\"\"\n",
    "    BasicDataset returns a pair of image and labels (targets).\n",
    "    If targets are not given, BasicDataset returns None as the label.\n",
    "    This class supports strong augmentation for Fixmatch,\n",
    "    and return both weakly and strongly augmented images.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 alg,\n",
    "                 lb_data,\n",
    "                 ulb_data,\n",
    "                 lb_targets=None,                 \n",
    "                 ulb_targets=None,\n",
    "                 num_classes=None,\n",
    "                 transform=None,\n",
    "                 is_ulb=False,\n",
    "                 strong_transform=None,\n",
    "                 onehot=False,\n",
    "                 *args, \n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Args\n",
    "            data: x_data\n",
    "            targets: y_data (if not exist, None)\n",
    "            num_classes: number of label classes\n",
    "            transform: basic transformation of data\n",
    "            use_strong_transform: If True, this dataset returns both weakly and strongly augmented images.\n",
    "            strong_transform: list of transformation functions for strong augmentation\n",
    "            onehot: If True, label is converted into onehot vector.\n",
    "        \"\"\"\n",
    "        super(BasicDataset2, self).__init__()\n",
    "        self.alg = alg\n",
    "        self.lb_data = lb_data\n",
    "        self.ulb_data = ulb_data\n",
    "        self.lb_targets = lb_targets\n",
    "        self.ulb_targets = ulb_targets\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.is_ulb = is_ulb\n",
    "        self.onehot = onehot\n",
    "        print(\"1-self.alg: \", self.alg)\n",
    "\n",
    "        self.transform = transform\n",
    "        self.strong_transform = strong_transform\n",
    "        if self.strong_transform is None:\n",
    "            if self.is_ulb:\n",
    "                assert self.alg not in ['fullysupervised', 'supervised', 'pseudolabel', 'vat', 'pimodel', 'meanteacher', 'mixmatch'], f\"alg {self.alg} requires strong augmentation\"\n",
    "    \n",
    "    def __lb_sample__(self, idx):\n",
    "        \"\"\" dataset specific sample function \"\"\"\n",
    "        # set idx-th target\n",
    "        # if self.lb_targets is None:\n",
    "        #     lb_target = None\n",
    "        # else:\n",
    "        lb_target_ = self.lb_targets[idx]\n",
    "        lb_target = lb_target_ if not self.onehot else get_onehot(self.num_classes, lb_target_)\n",
    "\n",
    "        # set augmented images\n",
    "        img = self.lb_data[idx]\n",
    "        # print(\"self.lb_data[idx]: \",self.lb_data[idx])\n",
    "        return img, lb_target\n",
    "    def __ulb_sample__(self, idx):\n",
    "        \"\"\" dataset specific sample function \"\"\"\n",
    "        # set idx-th target\n",
    "        # if self.lb_targets is None:\n",
    "        #     lb_target = None\n",
    "        # else:\n",
    "        #     lb_target_ = self.lb_targets[idx]\n",
    "        #     lb_target = target_ if not self.onehot else get_onehot(self.num_classes, target_)\n",
    "\n",
    "        # set augmented images\n",
    "        img = self.ulb_data[idx]\n",
    "        return img\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        If strong augmentation is not used,\n",
    "            return weak_augment_image, target\n",
    "        else:\n",
    "            return weak_augment_image, strong_augment_image, target\n",
    "        \"\"\"\n",
    "        lb_img, lb_target = self.__lb_sample__(idx)\n",
    "        ulb_img = self.__ulb_sample__(idx)\n",
    "\n",
    "        if self.transform is None:\n",
    "            return  {'x_lb':  transforms.ToTensor()(img), 'y_lb': lb_target}\n",
    "        else:\n",
    "            if isinstance(lb_img, np.ndarray):\n",
    "                lb_img = Image.fromarray(lb_img)\n",
    "            img_w = self.transform(lb_img)\n",
    "            return {'idx_lb': idx, \n",
    "                    'x_lb': img_w, \n",
    "                    'y_lb': lb_target,\n",
    "                    'idx_ulb': idx,\n",
    "                    'x_ulb_w': img_w, \n",
    "                    'x_ulb_s': self.strong_transform( Image.fromarray(ulb_img))} \n",
    "            # if not self.is_ulb:\n",
    "            #     return {'idx_lb': idx, 'x_lb': img_w, 'y_lb': target} \n",
    "            # else:\n",
    "            #     if self.alg == 'fullysupervised' or self.alg == 'supervised':\n",
    "            #         return {'idx_ulb': idx}\n",
    "            #     elif self.alg == 'pseudolabel' or self.alg == 'vat':\n",
    "            #         return {'idx_ulb': idx, 'x_ulb_w':img_w} \n",
    "            #     elif self.alg == 'pimodel' or self.alg == 'meanteacher' or self.alg == 'mixmatch':\n",
    "            #         # NOTE x_ulb_s here is weak augmentation\n",
    "            #         return {'idx_ulb': idx, 'x_ulb_w': img_w, 'x_ulb_s': self.transform(img)}\n",
    "            #     elif self.alg == 'remixmatch':\n",
    "            #         rotate_v_list = [0, 90, 180, 270]\n",
    "            #         rotate_v1 = np.random.choice(rotate_v_list, 1).item()\n",
    "            #         img_s1 = self.strong_transform(img)\n",
    "            #         img_s1_rot = torchvision.transforms.functional.rotate(img_s1, rotate_v1)\n",
    "            #         img_s2 = self.strong_transform(img)\n",
    "            #         return {'idx_ulb': idx, 'x_ulb_w': img_w, 'x_ulb_s_0': img_s1, 'x_ulb_s_1':img_s2, 'x_ulb_s_0_rot':img_s1_rot, 'rot_v':rotate_v_list.index(rotate_v1)}\n",
    "            #     elif self.alg == 'comatch':\n",
    "            #         return {'idx_ulb': idx, 'x_ulb_w': img_w, 'x_ulb_s_0': self.strong_transform(img), 'x_ulb_s_1':self.strong_transform(img)} \n",
    "            #     else:\n",
    "            #         return {'idx_ulb': idx, 'x_ulb_w': img_w, 'x_ulb_s': self.strong_transform(img)} \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ulb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e37d737-29de-4bfa-bc6d-bc4f48a7db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = {}, {}\n",
    "mean['cifar10'] = [0.485, 0.456, 0.406]\n",
    "mean['cifar100'] = [x / 255 for x in [129.3, 124.1, 112.4]]\n",
    "\n",
    "std['cifar10'] = [0.229, 0.224, 0.225]\n",
    "std['cifar100'] = [x / 255 for x in [68.2, 65.4, 70.4]]\n",
    "\n",
    "\n",
    "def get_cifar(args, alg, name, num_labels, num_classes, data_dir='./data', include_lb_to_ulb=True):\n",
    "    \n",
    "    data_dir = os.path.join(data_dir, name.lower())\n",
    "    dset = getattr(torchvision.datasets, name.upper())\n",
    "    dset = dset(data_dir, train=True, download=True)\n",
    "    data, targets = dset.data, dset.targets\n",
    "    \n",
    "    crop_size = args.img_size\n",
    "    crop_ratio = args.crop_ratio\n",
    "\n",
    "    transform_weak = transforms.Compose([\n",
    "        transforms.Resize(crop_size),\n",
    "        transforms.RandomCrop(crop_size, padding=int(crop_size * (1 - crop_ratio)), padding_mode='reflect'),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean[name], std[name])\n",
    "    ])\n",
    "\n",
    "    transform_strong = transforms.Compose([\n",
    "        transforms.Resize(crop_size),\n",
    "        transforms.RandomCrop(crop_size, padding=int(crop_size * (1 - crop_ratio)), padding_mode='reflect'),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        RandAugment(3, 5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean[name], std[name])\n",
    "    ])\n",
    "\n",
    "    transform_val = transforms.Compose([\n",
    "        transforms.Resize(crop_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean[name], std[name],)\n",
    "    ])\n",
    "\n",
    "    lb_data, lb_targets, ulb_data, ulb_targets = split_ssl_data(args, data, targets, num_classes, \n",
    "                                                                lb_num_labels=num_labels,\n",
    "                                                                ulb_num_labels=args.ulb_num_labels,\n",
    "                                                                lb_imbalance_ratio=args.lb_imb_ratio,\n",
    "                                                                ulb_imbalance_ratio=args.ulb_imb_ratio,\n",
    "                                                                include_lb_to_ulb=include_lb_to_ulb)\n",
    "    \n",
    "    lb_count = [0 for _ in range(num_classes)]\n",
    "    ulb_count = [0 for _ in range(num_classes)]\n",
    "    for c in lb_targets:\n",
    "        lb_count[c] += 1\n",
    "    for c in ulb_targets:\n",
    "        ulb_count[c] += 1\n",
    "    # print(\"lb_targets: \",lb_targets)\n",
    "    # print(\"ulb_targets: \",ulb_targets)\n",
    "    print(\"lb count: {}\".format(lb_count))\n",
    "    print(\"ulb count: {}\".format(ulb_count))\n",
    "    # lb_count = lb_count / lb_count.sum()\n",
    "    # ulb_count = ulb_count / ulb_count.sum()\n",
    "    # args.lb_class_dist = lb_count\n",
    "    # args.ulb_class_dist = ulb_count\n",
    "\n",
    "    if alg == 'fullysupervised':\n",
    "        lb_data = data\n",
    "        lb_targets = targets\n",
    "        # if len(ulb_data) == len(data):\n",
    "        #     lb_data = ulb_data \n",
    "        #     lb_targets = ulb_targets\n",
    "        # else:\n",
    "        #     lb_data = np.concatenate([lb_data, ulb_data], axis=0)\n",
    "        #     lb_targets = np.concatenate([lb_targets, ulb_targets], axis=0)\n",
    "    \n",
    "    # output the distribution of labeled data for remixmatch\n",
    "    # count = [0 for _ in range(num_classes)]\n",
    "    # for c in lb_targets:\n",
    "    #     count[c] += 1\n",
    "    # dist = np.array(count, dtype=float)\n",
    "    # dist = dist / dist.sum()\n",
    "    # dist = dist.tolist()\n",
    "    # out = {\"distribution\": dist}\n",
    "    # output_file = r\"./data_statistics/\"\n",
    "    # output_path = output_file + str(name) + '_' + str(num_labels) + '.json'\n",
    "    # if not os.path.exists(output_file):\n",
    "    #     os.makedirs(output_file, exist_ok=True)\n",
    "    # with open(output_path, 'w') as w:\n",
    "    #     json.dump(out, w)\n",
    "\n",
    "    lb_dset = BasicDataset(alg, lb_data, lb_targets, num_classes, transform_weak, False, None, False)\n",
    "\n",
    "    ulb_dset = BasicDataset(alg, ulb_data, ulb_targets, num_classes, transform_weak, True, transform_strong, False)\n",
    "\n",
    "    dset = getattr(torchvision.datasets, name.upper())\n",
    "    dset = dset(data_dir, train=False, download=True)\n",
    "    test_data, test_targets = dset.data, dset.targets\n",
    "    eval_dset = BasicDataset(alg, test_data, test_targets, num_classes, transform_val, False, None, False)\n",
    "\n",
    "    return lb_dset, ulb_dset, eval_dset\n",
    "\n",
    "def get_cifar2(args, alg, name, num_labels, num_classes, data_dir='./data', include_lb_to_ulb=True):\n",
    "    \n",
    "    data_dir = os.path.join(data_dir, name.lower())\n",
    "    dset = getattr(torchvision.datasets, name.upper())\n",
    "    dset = dset(data_dir, train=True, download=True)\n",
    "    data, targets = dset.data, dset.targets\n",
    "    \n",
    "    crop_size = args.img_size\n",
    "    crop_ratio = args.crop_ratio\n",
    "\n",
    "    transform_weak = transforms.Compose([\n",
    "        transforms.Resize(crop_size),\n",
    "        transforms.RandomCrop(crop_size, padding=int(crop_size * (1 - crop_ratio)), padding_mode='reflect'),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean[name], std[name])\n",
    "    ])\n",
    "\n",
    "    transform_strong = transforms.Compose([\n",
    "        transforms.Resize(crop_size),\n",
    "        transforms.RandomCrop(crop_size, padding=int(crop_size * (1 - crop_ratio)), padding_mode='reflect'),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        RandAugment(3, 5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean[name], std[name])\n",
    "    ])\n",
    "\n",
    "    transform_val = transforms.Compose([\n",
    "        transforms.Resize(crop_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean[name], std[name],)\n",
    "    ])\n",
    "\n",
    "    lb_data, lb_targets, ulb_data, ulb_targets = split_ssl_data(args, data, targets, num_classes, \n",
    "                                                                lb_num_labels=num_labels,\n",
    "                                                                ulb_num_labels=args.ulb_num_labels,\n",
    "                                                                lb_imbalance_ratio=args.lb_imb_ratio,\n",
    "                                                                ulb_imbalance_ratio=args.ulb_imb_ratio,\n",
    "                                                                include_lb_to_ulb=include_lb_to_ulb)\n",
    "    \n",
    "    lb_count = [0 for _ in range(num_classes)]\n",
    "    ulb_count = [0 for _ in range(num_classes)]\n",
    "    for c in lb_targets:\n",
    "        lb_count[c] += 1\n",
    "    for c in ulb_targets:\n",
    "        ulb_count[c] += 1\n",
    "    # print(\"lb_targets: \",lb_targets)\n",
    "    # print(\"ulb_targets: \",ulb_targets)\n",
    "    print(\"lb count: {}\".format(lb_count))\n",
    "    print(\"ulb count: {}\".format(ulb_count))\n",
    "    # lb_count = lb_count / lb_count.sum()\n",
    "    # ulb_count = ulb_count / ulb_count.sum()\n",
    "    # args.lb_class_dist = lb_count\n",
    "    # args.ulb_class_dist = ulb_count\n",
    "\n",
    "    if alg == 'fullysupervised':\n",
    "        lb_data = data\n",
    "        lb_targets = targets\n",
    "        # if len(ulb_data) == len(data):\n",
    "        #     lb_data = ulb_data \n",
    "        #     lb_targets = ulb_targets\n",
    "        # else:\n",
    "        #     lb_data = np.concatenate([lb_data, ulb_data], axis=0)\n",
    "        #     lb_targets = np.concatenate([lb_targets, ulb_targets], axis=0)\n",
    "    \n",
    "    # output the distribution of labeled data for remixmatch\n",
    "    # count = [0 for _ in range(num_classes)]\n",
    "    # for c in lb_targets:\n",
    "    #     count[c] += 1\n",
    "    # dist = np.array(count, dtype=float)\n",
    "    # dist = dist / dist.sum()\n",
    "    # dist = dist.tolist()\n",
    "    # out = {\"distribution\": dist}\n",
    "    # output_file = r\"./data_statistics/\"\n",
    "    # output_path = output_file + str(name) + '_' + str(num_labels) + '.json'\n",
    "    # if not os.path.exists(output_file):\n",
    "    #     os.makedirs(output_file, exist_ok=True)\n",
    "    # with open(output_path, 'w') as w:\n",
    "    #     json.dump(out, w)\n",
    "\n",
    "    lb_and_ulb_dset = BasicDataset2(alg,\n",
    "                         lb_data = lb_data,\n",
    "                         ulb_data=ulb_data, \n",
    "                         lb_targets = lb_targets,\n",
    "                         ulb_targets=ulb_targets,\n",
    "                         num_classes=num_classes,\n",
    "                         transform=transform_weak, \n",
    "                         is_ulb=True, \n",
    "                         strong_transform=transform_strong,\n",
    "                         onehot=False)\n",
    "    '''\n",
    "    transform=None,\n",
    "     is_ulb=False,\n",
    "     strong_transform=None,\n",
    "     onehot=False,\n",
    "     *args, \n",
    "     **kwargs\n",
    "    '''\n",
    "\n",
    "    dset = getattr(torchvision.datasets, name.upper())\n",
    "    dset = dset(data_dir, train=False, download=True)\n",
    "    test_data, test_targets = dset.data, dset.targets\n",
    "    eval_dset = BasicDataset(alg, test_data, test_targets, num_classes, transform_val, False, None, False)\n",
    "\n",
    "    return lb_and_ulb_dset, eval_dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7435ad-0a80-4759-ad79-9108b848017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_cifar(args, None, 'cifar10', 20, 10, data_dir='./data', include_lb_to_ulb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1f9e63-59b0-4879-b9a1-e1337599eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[0][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc633b7-22aa-4119-a566-19594de60c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[1][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a6a4247-4803-451e-97be-a035039fa217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dset, eval_dset =  get_cifar2(args, None, 'cifar10', 20, 10, data_dir='./data', include_lb_to_ulb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "933945fb-4ab6-4a2f-acf4-6665f2b472f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from semilearn.core.utils import get_dataset, get_data_loader, get_optimizer, get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9bdb7ce-12aa-421d-9f0d-698b6d76e233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_lb_ulb_loader = get_data_loader(args, dset, args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9f7ef02-899e-4d34-8b36-e51d50503ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in train_lb_ulb_loader:\n",
    "#     print(d.keys())\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762273d4-877c-4da0-9049-b318161066e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usb",
   "language": "python",
   "name": "usb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
